{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n",
    "import sys\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import importlib\n",
    "import smlmodule\n",
    "\n",
    "from itertools import combinations\n",
    "from pprint import pprint\n",
    "\n",
    "\"\"\"\n",
    "https://bmjopen.bmj.com/content/10/9/e039338\n",
    "\n",
    "We have computed the number of COVID-19 infected people for each province and the infection \n",
    "rate based on the number of inhabitants from February 24th to March 13th (the date when the \n",
    "lockdown was decided), as reported by the official government website, updated with daily \n",
    "frequency.34 The number of PM exceedances were computed between February 9th and February 29th, \n",
    "as we had to take into account the maximum lag period of 14 days, which is the average time \n",
    "elapsed between the contagion and the first weeks of the Italian epidemic \n",
    "(February 24th to March 13th). \n",
    "\n",
    "period1 = ['2020-02-09', '2020-02-28'] # YEAR-MONTH-DAY --->>> CASI COVID ['2020-02-24', '2020-03-13']\n",
    "\n",
    "period2 = ['2020-02-09', '2020-03-06] # YEAR-MONTH-DAY --->>> CASI COVID ['2020-02-09', '2020-03-21']\n",
    "period3 = ['2020-08-29', '2020-09-01'] # YEAR-MONTH-DAY --->>> CASI COVID ['2020-09-12', '2020-10-15']\n",
    "period4 = ['2020-08-29', '2020-10-30'] # YEAR-MONTH-DAY --->>> CASI COVID ['2020-09-12', '2020-11-14']\n",
    "period5 = ['2020-05-15', '2020-08-15'] # YEAR-MONTH-DAY --->>> CASI COVID ['2020-06-01', '2020-09-01']\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "LIMIT = 0.95\n",
    "\n",
    "verbose = False\n",
    "paperpath = \"./data/particulate.csv\"\n",
    "agefeatspath = \"./data/provinceages.csv\"\n",
    "deprividxpath = \"./data/ID11_prov21.xlsx\"\n",
    "tabellecodicipath = \"./data/TabelleCodici.xlsx\"\n",
    "copernicopath = \"./data/name_region_province_statistics_2020.csv\"\n",
    "\n",
    "__provmaps__ = {\n",
    "    \"bolzano_bozen\": \"bolzano\",\n",
    "    \"bolzanobozen\": \"bolzano\",\n",
    "    \"vibovalentia\": \"vibo_valentia\",\n",
    "    \"laquila\": \"l_aquila\",\n",
    "    \"laspezia\": \"la_spezia\",\n",
    "    \"barlettaandriatrani\": \"bat\",\n",
    "    \"ascolipiceno\": \"ascoli_piceno\",\n",
    "    \"carboniaiglesias\": \"carbonia\",\n",
    "    \"reggioemilia\": \"reggio_nell_emilia\",\n",
    "    \"pesarourbino\": \"pesaro\",\n",
    "    \"monzabrianza\": \"monza\",\n",
    "    \"reggiocalabria\": \"reggio_di_calabria\",\n",
    "    \"forlicesena\": \"forli\",\n",
    "    \"massacarrara\": \"massa\",\n",
    "    \"verbanocusioossola\": \"verbania\",\n",
    "    \"verbano_cusio_ossola\": \"verbania\",\n",
    "    \"massa_carrara\": \"massa\",\n",
    "    \"monza_e_della_brianza\": \"monza\",\n",
    "    \"pesaro_e_urbino\": \"pesaro\",\n",
    "    \"forli__cesena\": \"forli\",\n",
    "    \"bolzano_/_bozen\": \"bolzano\",\n",
    "    \"barletta_andria_trani\": \"bat\",\n",
    "    \"sud_sardegna\": \"carbonia\",\n",
    "    \"forl√¨_cesena\": \"forli\"\n",
    "}\n",
    "\n",
    "pollutantsnames = \"avg_wco_period1_2020,\"+\\\n",
    "        \"avg_wnh3_period1_2020,\"+\\\n",
    "        \"avg_wnmvoc_period1_2020,\"+\\\n",
    "        \"avg_wno2_period1_2020,\"+\\\n",
    "        \"avg_wno_period1_2020,\"+\\\n",
    "        \"avg_wo3_period1_2020,\"+\\\n",
    "        \"avg_wpans_period1_2020,\"+\\\n",
    "        \"avg_wpm10_period1_2020,\"+\\\n",
    "        \"avg_wpm2p5_period1_2020,\"+\\\n",
    "        \"avg_wso2_period1_2020,\" +\\\n",
    "        \"sum_wnh3_ex_q75_period1_2020,\" +\\\n",
    "        \"sum_wnmvoc_ex_q75_period1_2020,\" +\\\n",
    "        \"sum_wno2_ex_q75_period1_2020,\" +\\\n",
    "        \"sum_wno_ex_q75_period1_2020,\" +\\\n",
    "        \"sum_wpans_ex_q75_period1_2020,\" +\\\n",
    "        \"sum_wpm10_ex_q75_period1_2020,\" +\\\n",
    "        \"sum_wpm2p5_ex_q75_period1_2020,\" +\\\n",
    "        \"sum_wo3_ex_q75_period1_2020,\" + \\\n",
    "        \"sum_wco_ex_q75_period1_2020,\" + \\\n",
    "        \"sum_wso2_ex_q75_period1_2020\"\n",
    "\n",
    "featurestobeused = \"density,\" + \\\n",
    "        \"commutersdensity,\" + \\\n",
    "        \"depriv,\" + \\\n",
    "        \"lat,\" + \\\n",
    "        \"Ratio0200ver65,\" + \\\n",
    "        \"sum_wpm10_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wpm2p5_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wco_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wnh3_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wnmvoc_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wno2_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wno_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wo3_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wpans_ex_q75_period1_2020,\"+\\\n",
    "        \"sum_wso2_ex_q75_period1_2020\"\n",
    "\n",
    "def filterprovname (inprov):\n",
    "    low = inprov.lower()\n",
    "    low = low.rstrip()\n",
    "    low = low.lstrip()\n",
    "    low = low.replace(\" \", \"_\")\n",
    "    low = low.replace(\"'\", \"_\")\n",
    "    low = low.replace(\"-\", \"_\")\n",
    "\n",
    "    return low\n",
    "\n",
    "def normalize_provname (indata, provcolumn, verbose):\n",
    "\n",
    "    dict_data = {}  \n",
    "    for c in indata.columns:\n",
    "        if verbose:\n",
    "            print(\"  \", c)\n",
    "        if c != provcolumn:\n",
    "            dict_data[c] = []\n",
    "    dict_data[\"prov\"] = []\n",
    "\n",
    "    for i, row in indata.iterrows():\n",
    "        for c in indata.columns:    \n",
    "            if c != provcolumn:\n",
    "                dict_data[c].append(row[c])\n",
    "            else:\n",
    "                low = filterprovname(row[c])\n",
    "                if low in __provmaps__:\n",
    "                    low = __provmaps__[low]\n",
    "\n",
    "                dict_data[\"prov\"].append(low)\n",
    "\n",
    "    #for v in dict_data:\n",
    "    #    print(v, \" \", len(dict_data[v]))\n",
    "\n",
    "    data = pd.DataFrame.from_dict(dict_data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = pd.ExcelFile(tabellecodicipath)\n",
    "\n",
    "idtoprov = {}\n",
    "province = tc.parse(\"Codice Provincia\")\n",
    "for val in province[[\"Codice Provincia\",\"Nome Provincia\"]].values:\n",
    "    if type(val[1]) != float:\n",
    "        idtoprov[int(val[0])] = val[1]\n",
    "        #print(int(val[0]), val[1])\n",
    "\n",
    "in_datapaper = pd.read_csv(paperpath, sep=\";\")\n",
    "in_deprividx =  pd.ExcelFile(deprividxpath).parse(\"Foglio1\")\n",
    "in_agefeatures = pd.read_csv(agefeatspath)\n",
    "in_agefeatures = in_agefeatures[in_agefeatures.Population2020 != 0.0]\n",
    "in_copernico = pd.read_csv(copernicopath)\n",
    "\n",
    "print(\"Paper data \")\n",
    "datapaper = normalize_provname(in_datapaper, \"Province\", False)\n",
    "print(\"Age features \")\n",
    "agefeatures = normalize_provname(in_agefeatures, \"Provincia\", False)\n",
    "print(\"Copernico data \") \n",
    "copernico = normalize_provname(in_copernico, \"nome_ita\", False)\n",
    "\n",
    "dict_deprividx = {}\n",
    "print(\"DrepivIdx name \")\n",
    "for c in in_deprividx.columns:\n",
    "    if verbose:\n",
    "        print(\"   \", c)   \n",
    "    dict_deprividx[c] = []\n",
    "dict_deprividx[\"prov\"] = []\n",
    "\n",
    "for i, row in in_deprividx.iterrows():\n",
    "    id = row[\"prov21\"]\n",
    "    prov = filterprovname(idtoprov[id])\n",
    "    \n",
    "    if prov in __provmaps__:\n",
    "        prov = __provmaps__[prov]\n",
    "    \n",
    "    #print(id, prov)\n",
    "    dict_deprividx[\"prov\"].append(prov)\n",
    "    for c in in_deprividx.columns:\n",
    "        dict_deprividx[c].append(row[c])\n",
    "\n",
    "\n",
    "deprividx = pd.DataFrame.from_dict(dict_deprividx)       \n",
    "\n",
    "provincelist = list(set(list(datapaper[\"prov\"].values)) & \\\n",
    "        set(list(deprividx[\"prov\"].values)) & \\\n",
    "        set(list(agefeatures[\"prov\"].values)) &\n",
    "        set(list(copernico[\"prov\"].values)))\n",
    "\n",
    "print(\"Province list: \")\n",
    "for i, p in enumerate(provincelist):\n",
    "    print(\"  \", i+1, \" \", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for prov in provincelist:\n",
    "    cases = datapaper[datapaper[\"prov\"] == prov][\"Cases\"].values[0]\n",
    "    popolazione = datapaper[datapaper[\"prov\"] == prov][\"Population\"].values[0]\n",
    "    pop2 = agefeatures[agefeatures[\"prov\"] == prov][\"Population2020\"].values[0]\n",
    "    diff = 100.0*(math.fabs(popolazione-pop2)/(popolazione))\n",
    "\n",
    "    # check Exceedances/StationsNum\n",
    "    Exceedances = datapaper[datapaper[\"prov\"] == prov][\"Exceedances\"].values[0] \n",
    "    StationsNum = datapaper[datapaper[\"prov\"] == prov][\"StationsNum\"].values[0] \n",
    "\n",
    "    #if diff < 5.0 :\n",
    "    #if cases > 0.0 and diff < 5.0 and StationsNum > 0:\n",
    "    if cases > 0.0 and diff < 5.0:\n",
    "        counter += 1\n",
    "        print(counter, prov)\n",
    "\n",
    "ylogpropcasi = []\n",
    "features_dict = {}\n",
    "\n",
    "for fn in (\"population\", \"density\", \"commutersdensity\", \"depriv\", \\\n",
    "    \"lat\", \"Ratio0200ver65\",\"exoverstation\"):\n",
    "    features_dict[fn] = np.zeros(counter, dtype=\"float64\")\n",
    "\n",
    "for fn in pollutantsnames.split(\",\"):\n",
    "    features_dict[fn] = np.zeros(counter, dtype=\"float64\")\n",
    "\n",
    "i = 0 \n",
    "for idx, prov in enumerate(provincelist):\n",
    "\n",
    "    cases = datapaper[datapaper[\"prov\"] == prov][\"Cases\"].values[0]\n",
    "    popolazione = datapaper[datapaper[\"prov\"] == prov][\"Population\"].values[0]\n",
    "    pop2 = agefeatures[agefeatures[\"prov\"] == prov][\"Population2020\"].values[0]\n",
    "\n",
    "    diff = 100.0*(math.fabs(popolazione-pop2)/(popolazione))\n",
    "\n",
    "    # check Exceedances/StationsNum\n",
    "    Exceedances = datapaper[datapaper[\"prov\"] == prov][\"Exceedances\"].values[0] \n",
    "    StationsNum = datapaper[datapaper[\"prov\"] == prov][\"StationsNum\"].values[0] \n",
    "    \n",
    "    ycasi = cases/popolazione\n",
    "\n",
    "    #if diff < 5.0:\n",
    "    #if cases > 0.0 and diff < 5.0 and StationsNum > 0:\n",
    "    if cases > 0.0 and diff < 5.0:\n",
    "        if ycasi == 0.0:\n",
    "           ylogpropcasi.append(-13.0) \n",
    "        else:\n",
    "            ylogpropcasi.append(math.log(ycasi)) # atural logarithm of different numbers\n",
    "\n",
    "        selected = copernico[copernico[\"prov\"] == prov]\n",
    "\n",
    "        features_dict[\"population\"][i] = popolazione\n",
    "        features_dict[\"density\"][i] = \\\n",
    "                    datapaper[datapaper[\"prov\"] == prov][\"Density\"].values[0]    \n",
    "        features_dict[\"commutersdensity\"][i] = \\\n",
    "                    datapaper[datapaper[\"prov\"] == prov][\"CommutersDensity\"].values[0]       \n",
    "        features_dict[\"lat\"][i] = \\\n",
    "                    datapaper[datapaper[\"prov\"] == prov][\"Lat\"].values[0]       \n",
    "        features_dict[\"depriv\"][i] = \\\n",
    "                    deprividx[deprividx[\"prov\"] == prov][\"ID_2011\"].values[0]\n",
    "        #print(idx, prov, agefeatures[agefeatures[\"prov\"] == prov])\n",
    "        features_dict[\"Ratio0200ver65\"][i] = \\\n",
    "                    agefeatures[agefeatures[\"prov\"] == prov][\"Ratio0200ver65\"].values[0]\n",
    "\n",
    "        for fn in pollutantsnames.split(\",\"):\n",
    "            val = selected[fn].values[0]\n",
    "            features_dict[fn][i] = val \n",
    "\n",
    "        #features_dict[\"exoverstation\"][i] = Exceedances/StationsNum\n",
    "\n",
    "\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nomalize values\n",
    "new_features_dict = {}\n",
    "for fn in features_dict:\n",
    "    #print(fn)\n",
    "    abs_max = np.amax(np.abs(features_dict[fn]))\n",
    "    if abs_max == 0.0:\n",
    "        print (fn, \" will be removed \")\n",
    "        print (features_dict[fn])\n",
    "    else:\n",
    "        new_features_dict[fn] = features_dict[fn] * (1.0 / abs_max)\n",
    "\n",
    "features_dict = new_features_dict\n",
    "\n",
    "highcorrelated = {}\n",
    "for i1, v1 in enumerate(features_dict):\n",
    "    highcorrelated[v1] = []\n",
    "    for i2, v2 in enumerate(features_dict):\n",
    "        #if v1 != v2 and i2 > i1:\n",
    "        if v1 != v2:\n",
    "            corr, _ = pearsonr(features_dict[v1], features_dict[v2])\n",
    "            if math.fabs(corr) > LIMIT:\n",
    "                highcorrelated[v1].append(v2)\n",
    "                #print(v1, v2, corr)\n",
    "\n",
    "    #if len(highcorrelated[v1]) > 0:\n",
    "    #    print(v1)\n",
    "    #    for fntr in highcorrelated[v1]:\n",
    "    #        print(\"   \", fntr)\n",
    "\n",
    "removedfeatures = []\n",
    "features = []\n",
    "for fn in featurestobeused.split(\",\"):\n",
    "    if fn in features_dict:\n",
    "        canadd = True\n",
    "        for fnin in features:\n",
    "            if fn in highcorrelated[fnin]:\n",
    "                canadd = False\n",
    "                break\n",
    "\n",
    "        if canadd:\n",
    "            print(\"Using: %30s\"%fn)\n",
    "            features.append(fn)\n",
    "        else:\n",
    "            removedfeatures.append(fn)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "for fn in removedfeatures:\n",
    "    print(\"Highly correlated removing %30s\"%fn)\n",
    "    for cf  in highcorrelated[fn]:\n",
    "        print(\"     \",cf)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finalfeaturestobeused = \"density,commutersdensity,exoverstation\"\n",
    "#features = finalfeaturestobeused.split(\",\")\n",
    "#listostack = [features_dict[v] for v in features]\n",
    "\n",
    "featuresused = features\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack (listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "smlmodule.rfregressors (X, Y , featuresused, N=50, plotname=\"rf_model_allfeatures_using_sum\", pout=sys.stdout, showplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(smlmodule)\n",
    "\n",
    "featuresused = features\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack (listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "bestf, bestmse = smlmodule.rfregressors_custom_optimizer (X, Y, inboot=[True])\n",
    "\n",
    "print(bestf, bestmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(bestf)\n",
    "\n",
    "featuresused = features\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack (listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "smlmodule.rfregressors (X, Y , featuresused, N=50, pout=sys.stdout, plotname=\"rf_model_allfeatures_opt_using_sum\",showplot=True, optimisedparams=bestf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(smlmodule)\n",
    "\n",
    "featuresused = []\n",
    "\n",
    "for f in features:\n",
    "    if f != \"lat\":\n",
    "        featuresused.append(f)\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack (listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "smlmodule.rfregressors (X, Y , featuresused, N=50, plotname=\"rf_model_nolat_using_sum\", pout=sys.stdout, showplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(smlmodule)\n",
    "\n",
    "featuresused = []\n",
    "\n",
    "for f in features:\n",
    "    if f != \"lat\":\n",
    "        featuresused.append(f)\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack(listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "bestf, bestmse = smlmodule.rfregressors_custom_optimizer (X, Y, inboot=[True])\n",
    "\n",
    "print(bestf, bestmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(smlmodule)\n",
    "\n",
    "featuresused = []\n",
    "\n",
    "for f in features:\n",
    "    if f != \"lat\":\n",
    "        featuresused.append(f)\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack (listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "smlmodule.rfregressors (X, Y , featuresused, N=50, pout=sys.stdout, plotname=\"rf_model_nolat_opt_using_sum\", showplot=True, optimisedparams=bestf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(smlmodule)\n",
    "\n",
    "featuresused = []\n",
    "\n",
    "for f in features:\n",
    "    if f != \"lat\" and f != \"commutersdensity\":\n",
    "        featuresused.append(f)\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack (listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "smlmodule.rfregressors (X, Y , featuresused, N=50, plotname=\"rf_model_nolat_nocom_using_sum\", pout=sys.stdout, showplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(smlmodule)\n",
    "\n",
    "featuresused = []\n",
    "\n",
    "for f in features:\n",
    "    if f != \"lat\" and f != \"commutersdensity\":\n",
    "        featuresused.append(f)\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack(listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "bestf, bestmse = smlmodule.rfregressors_custom_optimizer (X, Y, inboot=[True])\n",
    "\n",
    "print(bestf, bestmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(smlmodule)\n",
    "\n",
    "featuresused = []\n",
    "\n",
    "for f in features:\n",
    "    if f != \"lat\" and f != \"commutersdensity\":\n",
    "        featuresused.append(f)\n",
    "\n",
    "listostack = [features_dict[v] for v in featuresused]\n",
    "\n",
    "X = np.column_stack (listostack)\n",
    "Y = np.asanyarray(ylogpropcasi)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "smlmodule.rfregressors (X, Y , featuresused, N=50, pout=sys.stdout, plotname=\"rf_model_nolat_nocom_opt_using_sum\", showplot=True, optimisedparams=bestf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
